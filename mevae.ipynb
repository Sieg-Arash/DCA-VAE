{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !git clone https://github.com/edgarschnfld/CADA-VAE-PyTorch\n!git clone https://github.com/Sieg-Arash/MEVAE","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-05-26T00:49:40.443952Z","iopub.execute_input":"2021-05-26T00:49:40.444244Z","iopub.status.idle":"2021-05-26T00:49:48.427165Z","shell.execute_reply.started":"2021-05-26T00:49:40.444214Z","shell.execute_reply":"2021-05-26T00:49:48.426236Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'MEVAE'...\nremote: Enumerating objects: 106, done.\u001b[K\nremote: Counting objects: 100% (64/64), done.\u001b[K\nremote: Compressing objects: 100% (47/47), done.\u001b[K\nremote: Total 106 (delta 24), reused 55 (delta 16), pack-reused 42\u001b[K\nReceiving objects: 100% (106/106), 214.68 MiB | 37.84 MiB/s, done.\nResolving deltas: 100% (33/33), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"# !pip install -r /kaggle/working/graduation-project-/CADAVAE/requirements.txt","metadata":{"execution":{"iopub.status.busy":"2021-05-26T00:49:48.430955Z","iopub.execute_input":"2021-05-26T00:49:48.431218Z","iopub.status.idle":"2021-05-26T00:49:48.434573Z","shell.execute_reply.started":"2021-05-26T00:49:48.431190Z","shell.execute_reply":"2021-05-26T00:49:48.433738Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!rm -rf DCA-VAE/.git","metadata":{"execution":{"iopub.status.busy":"2021-05-26T00:49:48.436308Z","iopub.execute_input":"2021-05-26T00:49:48.436674Z","iopub.status.idle":"2021-05-26T00:49:49.068109Z","shell.execute_reply.started":"2021-05-26T00:49:48.436637Z","shell.execute_reply":"2021-05-26T00:49:49.067210Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"cd /kaggle/working/MEVAE","metadata":{"execution":{"iopub.status.busy":"2021-05-26T00:49:49.071468Z","iopub.execute_input":"2021-05-26T00:49:49.071738Z","iopub.status.idle":"2021-05-26T00:49:49.078130Z","shell.execute_reply.started":"2021-05-26T00:49:49.071708Z","shell.execute_reply":"2021-05-26T00:49:49.077180Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/MEVAE\n","output_type":"stream"}]},{"cell_type":"code","source":"!mkdir data","metadata":{"execution":{"iopub.status.busy":"2021-05-26T00:49:49.081577Z","iopub.execute_input":"2021-05-26T00:49:49.082152Z","iopub.status.idle":"2021-05-26T00:49:49.701804Z","shell.execute_reply.started":"2021-05-26T00:49:49.082113Z","shell.execute_reply":"2021-05-26T00:49:49.700938Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"cd data","metadata":{"execution":{"iopub.status.busy":"2021-05-26T00:49:49.703428Z","iopub.execute_input":"2021-05-26T00:49:49.703761Z","iopub.status.idle":"2021-05-26T00:49:49.712178Z","shell.execute_reply.started":"2021-05-26T00:49:49.703731Z","shell.execute_reply":"2021-05-26T00:49:49.709197Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/working/MEVAE/data\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget https://www.dropbox.com/sh/btoc495ytfbnbat/AAAaurkoKnnk0uV-swgF-gdSa?dl=0","metadata":{"execution":{"iopub.status.busy":"2021-05-26T00:49:49.714496Z","iopub.execute_input":"2021-05-26T00:49:49.714938Z","iopub.status.idle":"2021-05-26T00:50:09.209820Z","shell.execute_reply.started":"2021-05-26T00:49:49.714901Z","shell.execute_reply":"2021-05-26T00:50:09.209016Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"--2021-05-26 00:49:50--  https://www.dropbox.com/sh/btoc495ytfbnbat/AAAaurkoKnnk0uV-swgF-gdSa?dl=0\nResolving www.dropbox.com (www.dropbox.com)... 162.125.9.18, 2620:100:601f:18::a27d:912\nConnecting to www.dropbox.com (www.dropbox.com)|162.125.9.18|:443... connected.\nHTTP request sent, awaiting response... 301 Moved Permanently\nLocation: /sh/raw/btoc495ytfbnbat/AAAaurkoKnnk0uV-swgF-gdSa [following]\n--2021-05-26 00:49:50--  https://www.dropbox.com/sh/raw/btoc495ytfbnbat/AAAaurkoKnnk0uV-swgF-gdSa\nReusing existing connection to www.dropbox.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://uce5dce1c14abaea3a98af15854c.dl.dropboxusercontent.com/zip_download_get/AynkWWFzdHuuVmmzJ6GytDoqmZsEZXivslkgEuX33Fsslpk4Ex3vg93ZtIHeLWo_3ELZ_xhn5Sl9tvT-ALFz7ftN9o2p8_QTJagHzzJJUu7M_Q# [following]\n--2021-05-26 00:49:51--  https://uce5dce1c14abaea3a98af15854c.dl.dropboxusercontent.com/zip_download_get/AynkWWFzdHuuVmmzJ6GytDoqmZsEZXivslkgEuX33Fsslpk4Ex3vg93ZtIHeLWo_3ELZ_xhn5Sl9tvT-ALFz7ftN9o2p8_QTJagHzzJJUu7M_Q\nResolving uce5dce1c14abaea3a98af15854c.dl.dropboxusercontent.com (uce5dce1c14abaea3a98af15854c.dl.dropboxusercontent.com)... 162.125.9.15, 2620:100:601f:15::a27d:90f\nConnecting to uce5dce1c14abaea3a98af15854c.dl.dropboxusercontent.com (uce5dce1c14abaea3a98af15854c.dl.dropboxusercontent.com)|162.125.9.15|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1060712777 (1012M) [application/zip]\nSaving to: ‘AAAaurkoKnnk0uV-swgF-gdSa?dl=0’\n\nAAAaurkoKnnk0uV-swg 100%[===================>]   1012M  68.3MB/s    in 17s     \n\n2021-05-26 00:50:09 (60.1 MB/s) - ‘AAAaurkoKnnk0uV-swgF-gdSa?dl=0’ saved [1060712777/1060712777]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!mv AAAaurkoKnnk0uV-swgF-gdSa?dl=0 data.zip","metadata":{"execution":{"iopub.status.busy":"2021-05-26T00:50:09.212975Z","iopub.execute_input":"2021-05-26T00:50:09.213238Z","iopub.status.idle":"2021-05-26T00:50:09.944880Z","shell.execute_reply.started":"2021-05-26T00:50:09.213210Z","shell.execute_reply":"2021-05-26T00:50:09.943864Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"!unzip data.zip","metadata":{"execution":{"iopub.status.busy":"2021-05-26T00:50:09.946355Z","iopub.execute_input":"2021-05-26T00:50:09.946711Z","iopub.status.idle":"2021-05-26T00:50:16.856952Z","shell.execute_reply.started":"2021-05-26T00:50:09.946652Z","shell.execute_reply":"2021-05-26T00:50:16.855985Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Archive:  data.zip\nwarning:  stripped absolute path spec from /\nmapname:  conversion of  failed\n   creating: CUB/\n   creating: SUN/\n   creating: AWA2/\n   creating: AWA1/\n extracting: SUN/res101.mat          \n extracting: CUB/res101.mat          \n extracting: AWA1/res101.mat         \n extracting: AWA2/res101.mat         \n extracting: SUN/att_splits.mat      \n extracting: CUB/att_splits.mat      \n extracting: AWA2/att_splits.mat     \n extracting: AWA1/att_splits.mat     \n extracting: CUB/CUB_supporting_data.p  \n","output_type":"stream"}]},{"cell_type":"code","source":"cd ..","metadata":{"execution":{"iopub.status.busy":"2021-05-26T00:50:16.858426Z","iopub.execute_input":"2021-05-26T00:50:16.858790Z","iopub.status.idle":"2021-05-26T00:50:16.867832Z","shell.execute_reply.started":"2021-05-26T00:50:16.858759Z","shell.execute_reply":"2021-05-26T00:50:16.867199Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"/kaggle/working/MEVAE\n","output_type":"stream"}]},{"cell_type":"code","source":"!python3 single_experiment.py --dataset CUB --num_shots 0 --generalized False","metadata":{"execution":{"iopub.status.busy":"2021-05-26T00:50:16.870634Z","iopub.execute_input":"2021-05-26T00:50:16.870902Z","iopub.status.idle":"2021-05-26T00:50:46.827761Z","shell.execute_reply.started":"2021-05-26T00:50:16.870878Z","shell.execute_reply":"2021-05-26T00:50:46.826652Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"***\n22\nThe current working directory is\n/kaggle/working/MEVAE\nProject Directory:\n/kaggle/working/MEVAE\nData Path\n/kaggle/working/MEVAE/data\n_____\n/kaggle/working/MEVAE/data/CUB/res101.mat\nresnet_features 2048\nattributes 312\n/opt/conda/lib/python3.7/site-packages/torch/optim/adam.py:48: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n  super(Adam, self).__init__(params, defaults)\n/opt/conda/lib/python3.7/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n  warnings.warn(warning.format(ret))\ntrain for reconstruction\nepoch 0 | iter 0\t | loss 8494.\nepoch 0 | iter 50\t | loss 5280.\nepoch 0 | iter 100\t | loss 5009.\nepoch 1 | iter 0\t | loss 4668.\nepoch 1 | iter 50\t | loss 4255.\nepoch 1 | iter 100\t | loss 4017.\nepoch 2 | iter 0\t | loss 4345.\nepoch 2 | iter 50\t | loss 3904.\nepoch 2 | iter 100\t | loss 4349.\nepoch 3 | iter 0\t | loss 3911.\nepoch 3 | iter 50\t | loss 3625.\nepoch 3 | iter 100\t | loss 3711.\nepoch 4 | iter 0\t | loss 3803.\nepoch 4 | iter 50\t | loss 3812.\nepoch 4 | iter 100\t | loss 3856.\nepoch 5 | iter 0\t | loss 3570.\nepoch 5 | iter 50\t | loss 3746.\nepoch 5 | iter 100\t | loss 3604.\nepoch 6 | iter 0\t | loss 3441.\nepoch 6 | iter 50\t | loss 3389.\nepoch 6 | iter 100\t | loss 3447.\nepoch 7 | iter 0\t | loss 3511.\nepoch 7 | iter 50\t | loss 3470.\nepoch 7 | iter 100\t | loss 3403.\nepoch 8 | iter 0\t | loss 3775.\nepoch 8 | iter 50\t | loss 3533.\nepoch 8 | iter 100\t | loss 3777.\nepoch 9 | iter 0\t | loss 3427.\n^C\nTraceback (most recent call last):\n  File \"single_experiment.py\", line 174, in <module>\n    losses = model.train_vae()\n  File \"/kaggle/working/MEVAE/vaemodel.py\", line 255, in train_vae\n    loss = self.trainstep(data_from_modalities[0], data_from_modalities[1] ,label)\n  File \"/kaggle/working/MEVAE/vaemodel.py\", line 212, in trainstep\n    self.optimizer.zero_grad()\n  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py\", line 191, in zero_grad\n    p.grad.requires_grad_(False)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/tensor.py\", line 943, in grad\n    if type(self) is not Tensor and has_torch_function(relevant_args):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/overrides.py\", line 1090, in has_torch_function\n    for a in relevant_args\n  File \"/opt/conda/lib/python3.7/site-packages/torch/overrides.py\", line 1090, in <genexpr>\n    for a in relevant_args\nKeyboardInterrupt\n","output_type":"stream"}]},{"cell_type":"code","source":"from vaemodel import Model\nimport numpy as np\nimport pickle\nimport torch\nimport os\nimport argparse\n\n\nsaved_state = torch.load('./CADA_trained.pth.tar')\nhyperparameters = saved_state['hyperparameters']\nmodel = Model(hyperparameters)\nmodel.load_state_dict(saved_state['state_dict'])\nfor d in model.all_data_sources:\n    model.encoder[d].load_state_dict(saved_state['encoder'][d])\n    model.decoder[d].load_state_dict(saved_state['decoder'][d])\n    \nu,s,h,history = model.train_classifier()\n\n\nif hyperparameters['generalized']==True:\n    acc = [hi[2] for hi in history]\nelif hyperparameters['generalized']==False:\n    acc = [hi[1] for hi in history]\n\nprint(acc[-1])\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T00:50:46.829397Z","iopub.execute_input":"2021-05-26T00:50:46.829769Z","iopub.status.idle":"2021-05-26T00:50:47.657678Z","shell.execute_reply.started":"2021-05-26T00:50:46.829728Z","shell.execute_reply":"2021-05-26T00:50:47.655590Z"},"trusted":true},"execution_count":12,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-beac732e41a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msaved_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./CADA_trained.pth.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hyperparameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './CADA_trained.pth.tar'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: './CADA_trained.pth.tar'","output_type":"error"}]},{"cell_type":"code","source":"import sys\nfrom sklearn.metrics import accuracy_score\nfrom torch.utils.data import DataLoader,TensorDataset\nimport numpy as np\nimport torch\nimport torch.tensor as tensor\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport time\nfrom sklearn.manifold import TSNE\n%matplotlib inline\ndef plot_embedding(data, label, title):\n    x_min, x_max = np.min(data, 0), np.max(data, 0)\n    data = (data - x_min) / (x_max - x_min)\n\n    fig = plt.figure()\n    ax = plt.subplot(111)\n    for i in range(data.shape[0]):\n        plt.text(data[i, 0], data[i, 1], str(label[i]),\n                 color=plt.cm.Set1(label[i]/50),\n                 fontdict={'weight': 'bold', 'size': 9})\n    plt.xticks([])\n    plt.yticks([])\n    plt.title(title)\n    plt.savefig(\"tsne.svg\", format='svg')\n    plt.show()\ndef plot_confusion_matrix(cm, savename, title='Confusion Matrix', classes = None):\n\n    plt.figure(figsize=(12, 8), dpi=100)\n    np.set_printoptions(precision=2)\n\n    # 在混淆矩阵中每格的概率值\n    ind_array = np.arange(len(classes))\n    x, y = np.meshgrid(ind_array, ind_array)\n#     for x_val, y_val in zip(x.flatten(), y.flatten()):\n#         c = cm[y_val][x_val]\n#         if c > 0.001:\n#             plt.text(x_val, y_val, \"%0.2f\" % (c,), color='red', fontsize=15, va='center', ha='center')\n    \n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.binary)\n    plt.title(title)\n    plt.colorbar()\n    xlocations = np.array(range(len(classes)))\n    plt.xticks(xlocations, classes, rotation=90)\n    plt.yticks(xlocations, classes)\n    plt.ylabel('Actual label')\n    plt.xlabel('Predict label')\n    \n    # offset the tick\n    tick_marks = np.array(range(len(classes))) + 0.5\n    plt.gca().set_xticks(tick_marks, minor=True)\n    plt.gca().set_yticks(tick_marks, minor=True)\n    plt.gca().xaxis.set_ticks_position('none')\n    plt.gca().yaxis.set_ticks_position('none')\n    plt.grid(True, which='minor', linestyle='-')\n    plt.gcf().subplots_adjust(bottom=0.15)\n    \n    # show confusion matrix\n    plt.savefig(savename, format='svg')\n    plt.show()\nt0 = time.time()\ntest_seen_X=np.load(\"test_seen_X.npy\")\ntest_novel_X=np.load(\"test_novel_X.npy\")\nprint(test_seen_X.shape, test_novel_X.shape)\ntsne = TSNE(n_components=2, init='pca', random_state=0)\n# test_seen_X_tsne = tsne.fit_transform(test_seen_X)\ntest_novel_X_tsne = tsne.fit_transform(test_novel_X)\nnp.save(\"test_novel_X_tsne.npy\",test_novel_X_tsne)\n# test_novel_X_tsne = np.load(\"test_novel_X_tsne.npy\")\npredicted_label_zsl=np.load(\"predicted_label_zsl.npy\")\noriginal_label_zsl=np.load(\"original_label_zsl.npy\")\noriginal_label_zsl = np.array(original_label_zsl, dtype='int')\nprint(predicted_label_zsl.shape)\nprint(original_label_zsl.shape)\nplot_embedding(test_novel_X_tsne, original_label_zsl,\n                     't-SNE embedding of the digits (time %.2fs)'\n                     % (time.time() - t0))\nunique_labels = np.unique(original_label_zsl)\ncm = confusion_matrix(original_label_zsl, predicted_label_zsl)\nprint(cm.max())\nmax_cm = cm.max()\nlocaltime = time.asctime( time.localtime(time.time()) )\nplot_confusion_matrix(cm/max_cm, localtime[-13:-5]+\".svg\", title='confusion matrix', classes = unique_labels)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T00:50:47.658578Z","iopub.status.idle":"2021-05-26T00:50:47.658990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}